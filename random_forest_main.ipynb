{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "## Introduction and importing data\n",
    "This is the main file for the multilayer perceptron. Here we call all the necessary functions and train the neural network. Let's get started by first importing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import data_utils as du\n",
    "import learning_utils as lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported data (4363, 264) and labels (4363, 1).\n"
     ]
    }
   ],
   "source": [
    "data_file = 'kaggle_data/train_data.csv'\n",
    "labels_file = 'kaggle_data/train_labels.csv'\n",
    "\n",
    "data, labels = du.Import_Data(data_file, labels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "Here we remove all features with zero variance, since they're not useful and also because they will cause a division by zero during normalization. Normalization is done here using min-max method. After normalization we shuffle the data, in order for Keras to pick a decent training set and validation set. We do not need to split the data into test and train sets, since Keras has a build in method for doing that during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero variance features removed from data. Input shape: (4363, 264). Output shape: (4363, 260).\n"
     ]
    }
   ],
   "source": [
    "clean_data = du.Remove_Zero_Variance(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalized using min-max method. Range: [-0.007439011072311145, 0.992560988927689].\n"
     ]
    }
   ],
   "source": [
    "normalized_features = du.Normalize(clean_data, 'min-max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4363, 151)\n"
     ]
    }
   ],
   "source": [
    "pca = du.PCA_fit(normalized_features,0.999995)\n",
    "selected_train_features = du.PCA_transform(pca, normalized_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully shuffled\n"
     ]
    }
   ],
   "source": [
    "shuffled_features, shuffled_labels = du.Shuffle(selected_train_features, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#resampled_features, resampled_labels = du.Resample(shuffled_features, shuffled_labels)\n",
    "#train_features, test_features, train_labels, test_labels = du.Split_Data(resampled_features, resampled_labels, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split. Test data ratio = 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/Documents/Python-sketches/mlbp/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling complete\n",
      "(14438, 151)\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features, train_labels, test_labels = du.Split_Data(shuffled_features, shuffled_labels, 0.33)\n",
    "resampled_features, resampled_labels = du.Resample(train_features, train_labels)\n",
    "print(resampled_features.shape)\n",
    "#rf = lu.Learn_Random_Forest(resampled_features, resampled_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growing the random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/Documents/Python-sketches/mlbp/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf = lu.Learn_Random_Forest(resampled_features, resampled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lu.Predict(rf, test_features)\n",
    "accuracy = lu.Accuracy_Score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "validation_data_file = 'kaggle_data/test_data.csv'\n",
    "validation_data = pd.read_csv(data_file,header=None)\n",
    "\n",
    "clean_valid_data = du.Remove_Zero_Variance(validation_data)\n",
    "normalized_valid_data = du.Normalize(clean_valid_data, 'min-max')\n",
    "selected_valid_features = du.PCA_transform(pca, normalized_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_to_submit = lu.Predict(rf, test_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbp_py35",
   "language": "python",
   "name": "mlbp_py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
