{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "## Introduction and importing data\n",
    "This is the main file for the multilayer perceptron. Here we call all the necessary functions and train the neural network. Let's get started by first importing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import data_utils as du\n",
    "import learning_utils as lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported data (4363, 264) and labels (4363, 1).\n"
     ]
    }
   ],
   "source": [
    "data_file = 'kaggle_data/train_data.csv'\n",
    "labels_file = 'kaggle_data/train_labels.csv'\n",
    "\n",
    "data, labels = du.Import_Data(data_file, labels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "Here we remove all features with zero variance, since they're not useful and also because they will cause a division by zero during normalization. Normalization is done here using min-max method. After normalization we shuffle the data, in order for Keras to pick a decent training set and validation set. We do not need to split the data into test and train sets, since Keras has a build in method for doing that during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero variance features removed from data. Input shape: (4363, 264). Output shape: (4363, 260).\n"
     ]
    }
   ],
   "source": [
    "clean_data = du.Remove_Zero_Variance(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalized using min-max method. Range: [-0.007439011072311145, 0.992560988927689].\n"
     ]
    }
   ],
   "source": [
    "normalized_features = du.Normalize(clean_data, 'min-max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4363, 151)\n"
     ]
    }
   ],
   "source": [
    "pca = du.PCA_fit(normalized_features,0.999995)\n",
    "selected_train_features = du.PCA_transform(pca, normalized_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully shuffled\n"
     ]
    }
   ],
   "source": [
    "shuffled_features, shuffled_labels = du.Shuffle(selected_train_features, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split. Test data ratio = 0.33\n"
     ]
    }
   ],
   "source": [
    "resampled_features, resampled_labels = du.Resample(shuffled_features, shuffled_labels)\n",
    "train_features, test_features, train_labels, test_labels = du.Split_Data(resampled_features, resampled_labels, 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growing the random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9401961456690213, using parameters: {'estimator__max_depth': 13}\n"
     ]
    }
   ],
   "source": [
    "rf = lu.Learn_Random_Forest(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9576778504803007\n"
     ]
    }
   ],
   "source": [
    "predictions = lu.Predict(rf, test_features)\n",
    "accuracy = lu.Accuracy_Score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero variance features removed from data. Input shape: (4363, 264). Output shape: (4363, 260).\n",
      "Data normalized using min-max method. Range: [-0.007439011072311145, 0.992560988927689].\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "validation_data_file = 'kaggle_data/test_data.csv'\n",
    "validation_data = pd.read_csv(data_file,header=None)\n",
    "\n",
    "clean_valid_data = du.Remove_Zero_Variance(validation_data)\n",
    "normalized_valid_data = du.Normalize(clean_valid_data, 'min-max')\n",
    "selected_valid_features = du.PCA_transform(pca, normalized_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_to_submit = lu.Predict(rf, test_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
